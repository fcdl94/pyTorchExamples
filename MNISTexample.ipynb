{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "# torchvision.datasets.MNIST outputs a set of PIL images\n",
    "# We transform them to tensors\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load and transform data\n",
    "trainset = torchvision.datasets.MNIST('./mnist',\n",
    "                train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "train_size = len(trainset)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('./mnist',\n",
    "               train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_size = len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_result(model) :\n",
    "    model.to(device)\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    output = model(images)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    print('Labels: ', labels.cpu().numpy())\n",
    "    print('Predic: ', pred.cpu().numpy())\n",
    "    ##print('Batch shape: ', images.size())\n",
    "    show_batch(images.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Scheduler\n",
    "#https://discuss.pytorch.org/t/two-optimizers-for-one-model/11085/6\n",
    "class MultipleScheduler(object):\n",
    "    def __init__(self, *op):\n",
    "        self.optimizers = op\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for op in self.optimizers:\n",
    "            op.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for op in self.optimizers:\n",
    "            op.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 39530\n"
     ]
    }
   ],
   "source": [
    "#Basic Model\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(14*14*10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model1 = Model1()\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters())\n",
    "\n",
    "params = 0\n",
    "for arr in model1.parameters():\n",
    "    #print(arr.size())\n",
    "    pX = 1\n",
    "    for x in arr.size():\n",
    "        pX *= x\n",
    "    params += pX\n",
    "print(\"Number of parameters: \" + str(params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model that illustrate how to keep frozen weights while training\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(14*14*10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10,10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "m2 = Model2()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "#MODO1 https://discuss.pytorch.org/t/how-to-perform-finetuning-in-pytorch/419/8?u=fcdl94\n",
    "#In this way you can set different lr for each set of params\n",
    "optimizer2 = optim.Adam( [ {\"params\": m2.conv1.parameters(), 'lr': 0.01}, {\"params\": m2.fc1.parameters()}], lr= 0.1)\n",
    "\n",
    "#MODO2 -> suggested method to freeze only some layer here:\n",
    "#  https://pytorch.org/docs/master/notes/autograd.html#excluding-subgraphs-from-backward\n",
    "#optimizer = optim.Adam(m2.parameters())\n",
    "#for param in m2.conv1.parameters():\n",
    "#    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model that illustrate how to keep frozen weights while training\n",
    "class Model2BIS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2BIS, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(14*14*10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10,10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "m2 = Model2()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "#MODO1 https://discuss.pytorch.org/t/how-to-perform-finetuning-in-pytorch/419/8?u=fcdl94\n",
    "#In this way you can set different lr for each set of params\n",
    "ignored_params = list(map(id, m2.fc3.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params, m2.parameters())\n",
    "\n",
    "optimizer2A = torch.optim.SGD(base_params, lr=0.1, momentum=0.9)\n",
    "optimizer2B = torch.optim.SGD(m2.fc3.parameters(), lr=0, momentum=0)\n",
    "scheduler2A = torch.optim.lr_scheduler.StepLR(optimizer2A, 2)\n",
    "scheduler2B = torch.optim.lr_scheduler.StepLR(optimizer2B, 2)\n",
    "scheduler = MultipleScheduler(optimizer2A,optimizer2B)\n",
    "optimizer2 = scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model with list module\n",
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(14*14*10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.ModuleList([nn.Linear(10,10), nn.Linear(10,10)])\n",
    "        self.index = 0;\n",
    "    \n",
    "    def set_index(self, index ):\n",
    "        if(index >= 0 and index <= 1):\n",
    "            self.index = index\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3[self.index](x)\n",
    "        return x\n",
    "    \n",
    "model3= Model3()\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer3 = optim.Adam(model3.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with block module\n",
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(14*14*10, 20),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "        #for param in self.conv1.parameters():\n",
    "        #    param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "    \n",
    "model4 = Model4()\n",
    "criterion4 = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer4 = optim.Adam(filter( lambda p : p.requires_grad == True, model4.parameters()))\n",
    "optimizer4 = optim.Adam(model4.fcs.parameters()) #this also works (without setting to False the requires_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Model\n",
    "class Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model5, self).__init__()\n",
    "        self.c1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.f1 = nn.Linear(14*14*10, 20)\n",
    "        self.f2 = nn.Linear(20, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.c1(x)), 2)\n",
    "        x = x.view(-1, 14*14*10)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = self.f2(x)\n",
    "        return x\n",
    "    \n",
    "model5 = Model5()\n",
    "criterion5 = nn.CrossEntropyLoss()\n",
    "optimizer5 = optim.Adam(model1.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs=5):\n",
    "    model.to(device)\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(0, epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = trainloader\n",
    "                dataset_size = train_size\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = testloader\n",
    "                dataset_size = test_size\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "              # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                #to GPU\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in  testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1960, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.save(model1.state_dict(),'MNISTModel/modelSD1.pt' )\n",
    "#st_dict = torch.load('MNISTModel/modelSD1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model3.set_index(0)\n",
    "#train(model3, optimizer, criterion, 1)\n",
    "#model3.set_index(0)\n",
    "#sample_result(model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'fcs.0.weight', 'fcs.0.bias', 'fcs.2.weight', 'fcs.2.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model4.state_dict().keys()\n",
    "#model4.conv1.load_state_dict(torch.load(\"MNISTModel/modelSD1.pt\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1.requires_grad = True\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.8842\n",
      "val Loss: 0.2753 Acc: 0.9177\n",
      "Training complete in 3m 19s\n",
      "Labels:  [7 8 2 1]\n",
      "Predic:  [7 8 2 1]\n",
      "Conv1.equals= True\n",
      "fcs.equals= False\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Proof of working of method 2 (exclude from Optim. the freezing parameters)\n",
    "print(\"Conv1.requires_grad = \" + str(list(model4.conv1.parameters())[0].requires_grad))\n",
    "\n",
    "torch.save(model4.fcs.state_dict(), \"Model4BT.fcs.pt\" )\n",
    "torch.save(model4.conv1.state_dict(), \"Model4BT.conv1.pt\" )\n",
    "train(model4, optimizer4, criterion4, 1) #TRAIN\n",
    "sample_result(model4)                   #show results\n",
    "torch.save(model4.fcs.state_dict(), \"Model4AT.fcs.pt\" )\n",
    "torch.save(model4.conv1.state_dict(), \"Model4AT.conv1.pt\" )\n",
    "\n",
    "conv1_BT = torch.load(\"Model4BT.conv1.pt\")['weight']\n",
    "conv1_AT = torch.load(\"Model4AT.conv1.pt\")['weight']\n",
    "print(\"Conv1.equals= \" + str(torch.equal(conv1_BT,conv1_AT))) #returns True\n",
    "\n",
    "fcs_BT = torch.load(\"Model4BT.fcs.pt\")['0.weight']\n",
    "fcs_AT = torch.load(\"Model4AT.fcs.pt\")['0.weight']\n",
    "print(\"fcs.equals= \" + str(torch.equal(fcs_BT,fcs_AT))) #returns False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 2.3562 Acc: 0.1017\n",
      "val Loss: 2.3134 Acc: 0.0958\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 2.3578 Acc: 0.1026\n",
      "val Loss: 2.3247 Acc: 0.1009\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 2.3578 Acc: 0.1019\n",
      "val Loss: 2.3475 Acc: 0.1135\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 2.3597 Acc: 0.0998\n",
      "val Loss: 2.4106 Acc: 0.1032\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 2.3590 Acc: 0.1001\n",
      "val Loss: 2.3382 Acc: 0.1010\n",
      "Training complete in 2m 23s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6e1b4e6d8dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model2BT.fc1.pt\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m#show results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model2AT.fc3.pt\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model2AT.fc1.pt\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_result' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(m2.fc3.state_dict(), \"Model2BT.fc3.pt\" )\n",
    "torch.save(m2.fc1.state_dict(), \"Model2BT.fc1.pt\" )\n",
    "train(m2, optimizer2, criterion2, 5) #TRAIN\n",
    "sample_result(m2)                   #show results\n",
    "torch.save(m2.fc3.state_dict(), \"Model2AT.fc3.pt\" )\n",
    "torch.save(m2.fc1.state_dict(), \"Model2AT.fc1.pt\" )\n",
    "\n",
    "fc3_BT = torch.load(\"Model2BT.fc3.pt\")['weight']\n",
    "fc3_AT = torch.load(\"Model2AT.fc3.pt\")['weight']\n",
    "print(\"fc3.equals= \" + str(torch.equal(fc3_BT,fc3_AT))) #returns True\n",
    "\n",
    "fcs_BT = torch.load(\"Model2BT.fc1.pt\")['weight']\n",
    "fcs_AT = torch.load(\"Model2AT.fc1.pt\")['weight']\n",
    "print(\"fc2.equals= \" + str(torch.equal(fcs_BT,fcs_AT))) #returns False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['c1.weight', 'c1.bias', 'f1.weight', 'f1.bias', 'f2.weight', 'f2.bias'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = Model5()\n",
    "state5 = dict(model5.named_parameters())\n",
    "state5.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "##load parameter to another model with a translator dictionary\n",
    "\n",
    "params5 = model5.named_parameters()\n",
    "params4 = model4.named_parameters()\n",
    "\n",
    "dict_params5 = dict(params5)\n",
    "dict_params4 = dict(params4)\n",
    "\n",
    "\n",
    "translator = { \n",
    "    \"conv1.weight\" : \"c1.weight\",\n",
    "    \"conv1.bias\" : \"c1.bias\",\n",
    "    \"fcs.0.weight\" : \"f1.weight\",\n",
    "    \"fcs.0.bias\" : \"f1.bias\",\n",
    "    \"fcs.2.weight\" : \"f2.weight\",\n",
    "    \"fcs.2.bias\" : \"f2.bias\",\n",
    "}\n",
    "\n",
    "#for name4, param4 in params4:\n",
    "#    if name4 in translator:\n",
    "#        name5 = translator[name4]\n",
    "#        dict_params5[name5].data.copy_(param4.data)\n",
    "##OR\n",
    "for name4 in translator.keys():\n",
    "    name5 = translator[name4]\n",
    "    dict_params5[name5].data.copy_(dict_params4[name4].data)\n",
    "        \n",
    "        \n",
    "flag = True\n",
    "for key in translator.keys():\n",
    "    if not torch.equal(model5.state_dict()[translator[key]], model4.state_dict()[key]):\n",
    "        flag = False\n",
    "        \n",
    "print(str(flag))\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4: 93.26\n",
      "Model 5: 93.26\n"
     ]
    }
   ],
   "source": [
    "#train(model4, optimizer4, criterion4, 1)\n",
    "\n",
    "print(\"Model 4: \" + str(compute_accuracy(model4)))\n",
    "print(\"Model 5: \" + str(compute_accuracy(model5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.3409 Acc: 0.8919\n",
      "val Loss: 0.1636 Acc: 0.9490\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9612\n",
      "val Loss: 0.0910 Acc: 0.9722\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9743\n",
      "val Loss: 0.0761 Acc: 0.9780\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.0657 Acc: 0.9794\n",
      "val Loss: 0.0702 Acc: 0.9775\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.0530 Acc: 0.9844\n",
      "val Loss: 0.0700 Acc: 0.9787\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9868\n",
      "val Loss: 0.0765 Acc: 0.9769\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.0364 Acc: 0.9883\n",
      "val Loss: 0.0613 Acc: 0.9815\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9903\n",
      "val Loss: 0.0775 Acc: 0.9782\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9911\n",
      "val Loss: 0.0627 Acc: 0.9829\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 0.9919\n",
      "val Loss: 0.0667 Acc: 0.9822\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 0.9931\n",
      "val Loss: 0.0745 Acc: 0.9806\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.0185 Acc: 0.9942\n",
      "val Loss: 0.0752 Acc: 0.9824\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.0175 Acc: 0.9941\n",
      "val Loss: 0.0778 Acc: 0.9826\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.0154 Acc: 0.9953\n",
      "val Loss: 0.0927 Acc: 0.9797\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.0144 Acc: 0.9951\n",
      "val Loss: 0.0921 Acc: 0.9793\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 0.9955\n",
      "val Loss: 0.0947 Acc: 0.9813\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.0107 Acc: 0.9965\n",
      "val Loss: 0.1094 Acc: 0.9816\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 0.9961\n",
      "val Loss: 0.1103 Acc: 0.9793\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9967\n",
      "val Loss: 0.1215 Acc: 0.9800\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.0095 Acc: 0.9969\n",
      "val Loss: 0.1204 Acc: 0.9800\n",
      "Training complete in 8m 2s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a0f28fd6595b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-098e4cf9783f>\u001b[0m in \u001b[0;36msample_result\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/conda3/envs/MultiDomainLearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-ea2548cb5500>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#x = F.relu(self.conv1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/conda3/envs/MultiDomainLearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/conda3/envs/MultiDomainLearning/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "train(model1, optimizer1, criterion1, 20) #TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [8 0 0 1]\n",
      "Predic:  [8 0 0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_result(model1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
